# MultiModel_llama
chat with multi madel using llama 3.2
